<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="A half-day workshop at IEEE VIS 2023">
  <meta content='text/html; charset=UTF-8' http-equiv='Content-Type' />
  <meta name="twitter:site" content="@altVIS" />
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="img/altvis_square.jpg">
  <meta name="twitter:title" content="alt.VIS" />
  <meta property="og:title" content="alt.VIS" />
  <meta name="twitter:description" content="A half-day workshop at IEEE VIS 2023" />
  <meta property="og:description" content="A half-day workshop at IEEE VIS 2023" />
  <meta property="og:image:width" content="800" />
  <meta property="og:image:height" content="800" />
  <meta property="og:image" content="img/altvis_square.jpg" />
  <script src="https://kit.fontawesome.com/5e95ac832b.js" crossorigin="anonymous"></script>

  <title>alt.VIS</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="main.css" rel="stylesheet">

</head>

<body>
    <section class="text-center">
      <div id="logo"><h1><em>alt.</em><br>VIS</h1></div>
      <p class="lead">A half-day workshop at IEEE VIS 2023</p>
      <!-- <p>Oklahoma Station Room #7 and Online, Sunday October 16th 2022, 9am to 12pm CDT (UTC-5)</p> -->
    </div>
    <section>
      <p>Not all work that moves the field forward fits into the model of a standard conference paper or conference talk. The memorability or intellectual impact of work is often inextricably linked to this non-conventional form, whether it is a reflection, provocation, critique, satire, artistic statement, or manifesto. Successful venues like ACM CHI’s <a target="_blank" rel="noopener noreferrer" href="https://chi2021.acm.org/for-authors/presenting/alt-chi">alt.chi</a> (“a forum for controversial, risk-taking, and boundary pushing research at CHI”) and various “unconferences” have emerged in the past years as a way of providing an outlet for this sort of unconventional work.</p> <p>Visualization, and IEEE VIS specifically, which incorporates perspectives in the intersection between art and design, statistics and psychology, we believe is uniquely placed to both generate and value the non-traditional. What’s more, we observed a long-running desire for an outlet for non-traditional work among both long-time attendees as well as those researchers or practitioners who do not currently feel welcome or appreciated in the IEEE VIS environment.</p> <p>Therefore, based on the (often unexpected) utility of unconventional work, the long standing and successful models of “alternative” conferences, and an expressed interest in bringing these models to the IEEE VIS community, we founded an “alt.VIS” workshop in 2021 as a venue for work that is otherwise difficult to place in the main conference for reasons of form, format, or topic.</p>
      <p>The remit of this workshop, mirroring alt.CHI, is relatively broad both in terms of scope of topics and presentation types: our selection criteria are more focused on impact. What sort of work might cause the field to rethink its priorities or ways of operating? What work might highlight under-explored or neglected areas of visualization study or application? What, as per Kant, would “interrupt [our] dogmatic slumber” and stir us to action?
      </p>
    </section>
 
    <section class="feature">
        
      <h1>Schedule</h1>
      <table>
        <thead>
          <tr>
            <th>Time</th>
            <th>Content</th>
            <th>Presenter</th>
          </tr>
        </thead>
        <tbody>
          <tr class="session structural">
            <td>14:00 - 14:10</td>
            <td>Intro</td>
            <td>derya Akbaba</td>
          </tr>
          <tr class="session" id="InHere">
            <td>14:10 - 15:17</td>
            <td>First Paper Session: In Here</td>
            <td>Sara di Bartolomeo</td>
          </tr>
          <tr>
            <td>14:10 - 14:20</td>
            <td><a class='jumpto' href="#OnlyYou">Only YOU Can Make IEEE VIS Environmentally Sustainable</a></td>
            <td>Elsie Lee-Robbins </td>
          </tr>
          <tr>
            <td>14:20 - 14:34</td>
            <td><a class='jumpto' href="#DevOps">DevOps for DataVis: A Survey and Provocation for Teaching Deployment of Data Visualizations</a></td>
            <td>Jane Adams</td>
          </tr>
          <tr>
            <td>14:34 - 14:48</td>
            <td><a class='jumpto' href="#DataEmbroidery">Data embroidery with black-and-white textures</a></td>
            <td>Tingying He</td>
          </tr>
          <tr>
            <td>14:48 - 15:02</td>
            <td><a class='jumpto' href="#AerialSensor">Humanity Influenced Visualization Design for Aerial Sensor-based Visualization of Environmental Factors</a></td>
            <td>Elina Esenbaeva</td>
          </tr>
          <tr>
            <td>15:02 - 15:17</td>
            <td><a class='jumpto' href="#VisFutures">VisFutures</a></td>
            <td>Charles Perin</td>
          </tr>
          
          <tr class="session structural">
            <td>15:15 - 15:45</td>
            <td>Coffee Break</td>
            <td></td>
          </tr>
          <tr class="session">
            <td>15:45 - 17:00</td>
            <td>Second Paper Session: Out There</td>
            <td>Jane Adams</td>
          </tr>
          <tr>
            <td>15:45 - 15:59</td>
            <td><a class='jumpto' href="#WeirdEerie">Visualizing the Weird and the Eerie</a></td>
            <td>Matthew Brehmer</td>
          </tr>
          <tr>
            <td>15:59 - 16:13<br></td>
            <td><a class='jumpto' href="#nWalks">n Walks in the Fictional Woods</a></td>
            <td>Sara di Bartolomeo</td>
          </tr>
          <tr>
            <td>16:13 - 16:27</td>
            <td><a class='jumpto' href="#LSDvis">LSDvis: Hallucinatory data visualisations in real world environments</a><br></td>
            <td>Benjamin Lee</td>
          </tr>
          <tr>
            <td>16:27 - 16:41</td>
            <td><a class='jumpto' href="#Nonstandard">On nonstandard visualization</a></td>
            <td>Alex Ravsky</td>
          </tr>
          <tr class="session structural">
            <td>16:41 - 17:00</td>
            <td>Closing</td>
            <td>Derya Akbaba, Jane Adams and Sara di Bartolomeo</td>
          </tr>
        </tbody>
        </table>
    </section>

    <section>
      <h1>Accepted Papers</h1>
      <table>
        <tbody>
          <tr id="DevOps">
            <td class="teaser"><img src="teasers/2023/DevOps.png" alt="Chart showing the occurence of DevOps keywords in vis curricula."></td>
            <td class="abstract"><h3>DevOps for DataVis: A Survey and Provocation for Teaching Deployment of Data Visualizations</h3>
              <h5 class="award">Most Frustration-Motivated</h5>
              <i><a href="https://twitter.com/janelydiaadams" target="_blank">Jane Adams</a></i><br/><br/>
              <p> We present a provocation towards teaching development operations (“DevOps") and other infrastructure concepts in the course of collegiate data visualization instruction. We survey 65 syllabi from semester-long, college-level data visualization courses, with an eye toward languages and platforms used, as well as mentions of deployment related terms. Results convey significant variability in language and tooling used in curricula. We identify a distinct lack of discussions around ‘DevOps for DataVis’ scaffolding concepts such as version control, package management, server infrastructure, high-performance computing, and machine learning data pipelines. We acknowledge the challenges of adding supplemental information to already dense curricula, and the expectation that prior or concurrent classes should provide this computer science background. We propose a group community effort to create one free ‘course’ or ‘wiki’ as a living reference on the ways these broader DevOps concepts relate directly to data visualization specifically. A free copy of this paper and all supplemental materials are available at https://osf.io/bxaqz/</p>
              <a target="_blank" href="papers/2023/DevOps.pdf">PDF</a><br/>
              <a rel="noopener noreferrer" target="_blank" href="https://osf.io/bxaqz/">OSF</a>
            </td>
          </tr>

          <tr id="DataEmbroidery">
            <td class="teaser"><img src="teasers/2023/DataEmbroidery.png" alt="Teaser image showing a black and white, textured chart made of embroidery."></td>
            <td class="abstract"><h3>Data Embroidery with Black-and-White Textures</h3>
              <h5 class="award">Most Likely to be on Etsy Tomorrow</h5>
              <i>Tingying He, Petra Isenberg, Tobias Isenberg</i><br/><br/>
              <p> We investigated data embroidery with black-and-white textures, identifying challenges in the use of textures for machine embroidery based on our own experience. Data embroidery, as a method of physically representing data, offers a unique way to integrate personal data into one's everyday fabric-based objects. Owing to their monochromatic characteristics, black-and-white textures promise to be easy to employ in machine embroidery. We experimented with different textured visualizations designed by experts and, in this paper, we detail our workflow and evaluate the performance and suitability of different textures. We then conducted a survey on vegetable preferences within a family and created a canvas bag as a case study, featuring the embroidered family data to show how embroidered data can be used in practice.</p>
              <a target="_blank" href="papers/2023/DataEmbroidery.pdf">PDF</a><br/>
            </td>
          </tr>

          <tr id="LSDvis">
            <td class="teaser"><img src="teasers/2023/LSDvis.png" alt="Teaser image showing a Australian landscapes with visualizations projected on them."></td>
            <td class="abstract"><h3>LSDvis: Hallucinatory Data Visualisations in Real World Environments </h3>
              <h5 class="award">Albert Hofmann's Second Favorite</h5>
              <i>Ari Kouts, <a href="https://twitter.com/lonnibesancon" target="_blank">Lonni Besançon</a>, Michael Sedlmair, Dr Benjamin Lee</i><br/><br/>
              <p> We propose the concept of "LSDvis": the (highly exaggerated) visual blending of situated visualisations and the real-world environment to produce data representations that resemble hallucinations. Such hallucinatory visualisations incorporate elements of the physical environment, twisting and morphing their appearance such that they become part of the visualisation itself. We demonstrate LSDvis in a "proof of proof of concept", where we use Stable Diffusion to modify images of real environments with abstract data visualisations as input. We conclude by discussing considerations of LSDvis. We hope that our work promotes visualisation designs which deprioritise saliency in favour of quirkiness and ambience.</p>
              <a target="_blank" href="papers/2023/LSDvis.pdf">PDF</a><br/>
            </td>
          </tr>

          <tr id="OnlyYou">
            <td class="teaser"><img src="teasers/2023/OnlyYou.png" alt="Teaser image showing a watercolor painting of a data visualization catching fire."></td>
            <td class="abstract"><h3>Only YOU Can Make IEEE VIS Environmentally Sustainable</h3>
              <h5 class="award">Smokey's Favorite</h5>
              <i>Elsie Lee-Robbins, Andrew M McNutt</i><br/><br/>
              <p> The IEEE VIS Conference (or VIS) hosts more than 1000 people annually. It brings together visualization researchers and practitioners from across the world to share new research and knowledge. Behind the scenes, a team of volunteers puts together the entire conference and makes sure it runs smoothly. Organizing involves logistics of the conference, ensuring that the attendees have an enjoyable time, allocating rooms to multiple concurrent tracks, and keeping the conference within budget. In recent years, the COVID-19 pandemic has abruptly disrupted plans, forcing organizers to switch to virtual, hybrid, and satellite formats. These alternatives offer many benefits: fewer costs (e.g., travel, venue, institutional), greater accessibility (who can physically travel, who can get visas, who can get child care), and a lower carbon footprint (as people do not need to fly to attend). As many conferences begin to revert to the pre-pandemic status quo of primarily in-person conferences, we suggest that it is an opportune moment to reflect on the benefits and drawbacks of lower-carbon conference formats. To learn more about the logistics of conference organizing, we talked to 6 senior executive-level VIS organizers. We review some of the many considerations that go into planning, particularly with regard to how they influence decisions about alternative formats. We aim to start a discussion about the sustainability of VIS -- including sustainability for finance, volunteers, and, central to this work, the environment -- for the next three years and the next three hundred years.</p>
              <a target="_blank" href="papers/2023/OnlyYou.pdf">PDF</a><br/>
              <a rel="noopener noreferrer" target="_blank" href=" https://arxiv.org/abs/2308.15429 ">ArXiv</a>
            </td>
          </tr>

          <tr id="WeirdEerie">
            <td class="teaser"><img src="teasers/2023/WeirdEerie.png" alt="Teaser image showing a Weird and Eerie octopus."></td>
            <td class="abstract"><h3>Visualizing the Weird and the Eerie</h3>
              <h5 class="award">Most (k-)Punk</h5>
              <i>Matthew Brehmer</i><br/><br/>
              <p>In this brief essay, I reflect on how Mark Fisher's definitions of the weird and the eerie could be applied in communicative data visualization. I ask how visualization designers might elicit these two impressions when a viewer is engaging with multimodal representations of data. I argue that there are situations in which viewers should feel uncertain or suspicious of unseen forces that account for the presence or absence of audiovisual patterns. Finally, I conclude that the ability to appreciate the weird and the eerie in data is particularly important at this moment in history, one marked by significant ecological and economic disruption.</p>
              <a target="_blank" href="papers/2023/WeirdEerie.pdf">PDF</a><br/>
            </td>
          </tr>

          <tr id="AerialSensor">
            <td class="teaser"><img src="teasers/2023/AerialSensor.png" alt="Teaser image showing schematics for an Aerial Sensor"></td>
            <td class="abstract"><h3>Humanity Influenced Visualization Design for Aerial Sensor-based Visualization of Environmental Factor</h3>
              <h5 class="award">Most Interdisciplinary</h5>
              <i>Dr. and Prof. Brian J. d'Auriol, Elina Esenbaeva, Dana Nursultanova, Sabina Ualibekova, Suthipong Sthiannopkao </i><br/><br/>
              <p> The motivating perspective of this work is that visualization is a human endeavor as natural as human life is itself. This has profound influence on the way visualization is approached as the focus shifts away from any data-centric, visualization technique- or system-based foundations to one of human-centric visual perception, information perception, information acquisition and learning. This paper reports on part of a design of a visualization approach and system for deployments in wide-scope application areas of interest and which is guided by the Engineering Insightful Serviceable Visualization (EISV) model and is thus in the context of this human-centric perspective. The application areas are primarily loosely constrained environments, that are, environments for which available techniques such as computational modeling or fixed, location-based sensors are ill-suited. These environments have terrain, build or other similar features. An aerial drone-based sensor platform is proposed to sample environmental data in these environments. One of the included sensors on this platform is a LiDAR, a distance ranging sensor. The visual output of the LiDAR is primarily studied in this paper using the notions of iconicity and indexicality in the Peircean sense and guided by the EISV model. Several work-in-progress experiments that illustrate how the proposed system may respond are described. </p>
              <a target="_blank" href="papers/2023/AerialSensor.pdf">PDF</a><br/>
            </td>
          </tr>

          <tr id="Nonstandard">
            <td class="teaser"><img src="teasers/2023/Nonstandard.png" alt="Teaser image showing a circular non-Euclidian tesselation of lizards by MC Escher."></td>
            <td class="abstract"><h3>On Nonstandard Visualization</h3>
              <h5 class="award">Least Euclidian</h5>
              
              <i>Taras Banakh, Alex Ravsky</i><br/><br/>
              <p>We discuss the nonstandard (non-Euclidean, four-dimensional, of variable dimension, and with two-edged space placement) visualizations, their neurophysiological and philosophical possibilities, and ways to realize them.</p>
              <a target="_blank" href="papers/2023/Nonstandard.pdf">PDF</a><br/>
            </td>
          </tr>

          <tr id="nWalks">
            <td class="teaser"><img src="teasers/2023/nWalks.png" alt="Teaser image showing an abstracted forest."></td>
            <td class="abstract"><h3><i>n</i> Walks in the Fictional Woods</h3>
              <h5 class="award">Most Flânerific</h5>
              <i>Victor Schetinger, Sara Di Bartolomeo, Dr. Edirlei Soares de Lima, Christofer Meinecke, Rudolf Rosa</i><br/><br/>
              <p> This paper presents a novel exploration of the interaction between generative AI models, visualization, and narrative generation processes, using OpenAI's GPT as a case study. We look at the question <i>"Where Does Generativeness Comes From?"</i>, which has a simple answer at the intersection of many domains. Drawing on Umberto Eco's <i>"Six Walks in the Fictional Woods</i>, we engender a speculative, transdisciplinary scientific narrative using ChatGPT in different roles: as an information repository, a ghost writer, a scientific coach, among others. The paper is written as a piling of plateaus where the titling of each (sub-)section, the "teaser" images, the headers, and a biblock of text are strata forming a narrative about narratives. To enrich our exposition, we present a visualization prototype to analyze storyboarded narratives, and extensive conversations with ChatGPT. Each link to a ChatGPT conversation is an experiment on writing where we try to use different plugins and techniques to investigate the topics that, ultimately form the content of this portable document file. Our visualization uses a dataset of stories with scene descriptions, textual descriptions of scenes (both generated by ChatGPT), and images (generated by Stable Diffusion using scene descriptions as prompts). We employ a simple graph-node diagram to try to make a "forest of narratives" visible, an example of a vis4gen application that can be used to analyze the output of Large Languange + Image Models.</p>
              <a target="_blank" href="papers/2023/nWalks.pdf">PDF</a><br/>
              <a rel="noopener noreferrer" target="_blank" href="https://arxiv.org/abs/2308.06266">ArXiv</a>
            </td>
          </tr>

          <tr id="VisFutures">
            <td class="teaser"><img src="teasers/2023/VisFutures.png" alt="Teaser image showing instructions for a card game."></td>
            <td class="abstract"><h3>VisFutures</h3>
              <h5 class="award">Most Playable</h5>
              <i>Mackenzie Dalton, Charles Perin, Lora Oehlberg, Petra Isenberg, Sheelagh Carpendale, Wesley Willett</i><br/><br/>
              <p> Welcome to Vis Futures! ... where YOU have a say in how people use data in the Future!

                Vis Futures is a card-based sketching game where players think critically (and playfully) about the future of data and visualization. Players deal a set of cards that hint at a possible future, and a possible dataset in that future. Players then use those prompts to imagine and sketch new visualization designs and imagine ways that future people from a particular audience might encounter, interact with, or utilize data (quirks and all). At the end of each round, players share their visualizations, discuss, and vote on which scenarios and visualizations are the most creative!
                
                Our goal is to include more people (including visualization students, researchers, and practitioners, as well as clients and collaborators) in discussions of critical data issues that have implications for the future of data, visualization, and technology. This game encourages players to engage in future-forward design thinking, examining the increasingly complex implications of our relationships with data and technology, and considering how, where, and why visual representations of data might play a role. It can be pretty fun too!
                
                This submission consists of the instruction booklet that accompanies the game. The provided link contains as supplemental material the cards for the game as well as the optional creator pack. These will later be uploaded and available at the game's website provided in the instructions.</p>
              <a target="_blank" href="papers/2023/VisFutures.pdf">PDF</a><br/>
            </td>
          </tr>
        </tbody>
      </table>
    </section>

    <section class="greyed-out">
      <h1>Call for Submissions [CLOSED]</h1>
      <h4><i>Note: deadline extended!!</i></h4>
      We invite the submission  of <b><i>original</i></b> bold, provocative, unusual, unconventional, thought-provoking works related to visualization in the broad sense. The deadline for submissions is <s>June 30, 2023</s> <b>July 7 2023, End of Day (AoE)</b> on PCS. 
        Note that the submission itself does not need to have the form of a traditional conference paper: You are welcome to use any template format or medium that works for your submission (this can include, but is not limited to, the familiar <a target="_blank" href="https://tc.computer.org/vgtc/publications/conference/">TVCG conference format</a>). While alternative presentations (such as websites, videos, zines, or comics) are welcome, each work must include a PDF submission for archiving purposes including at least a title, author names*, an abstract. 
        Traditionally written works should be no longer than 4000 words (not including references). 
        Plagiarism (of any kind) will result in a rejection. 
        <!-- Notifications of acceptance will be shared by <b>Wednesday, August 31st, 2022</b>.</p> -->

      <p>Examples of submissions we encourage include (but are not limited to):</p>
      <ul>
      <li>Provocations, manifestos, or other critiques of visualization research and practice</li>
        <li>Creative and thought-provoking presentations of data (especially unconventional data), either as traditional visualizations or as multimedia presentations or artworks</li>
        <li>Novel and unconventional visualization techniques or design processes</li>
        <li>Hands-on activities and artworks of all mediums.</li>
        <li>(Kind and civil) critiques to other works.</li>
      </ul>
      <!-- <ul>
        <li><b>Position papers or ‘meta-papers’</b> that address topics such as: how mentors in the visualization community presently or should ideally respond to failure; implementation of iterative design principles to visualization research workflows; the role of community critique in development and evaluation of methods; pedagogical strategies; the development of ethical guidelines for visualization research standards; and the contextualization of alternative visualizations within VIS.</li>
        
        <li><b>Debates or panel discussions</b> among position paper authors and/or mid- or senior-level career visualization practitioners sharing: stories of personal experience with research failure; discussions about the role of VIS; ideas for improving community experience and engagement; well-elucidated frustrations; conversations about pedagogical strategy; and guest input from visualization practitioners. Call for panelists will launch immediately pending workshop acceptance; debates will be formed around accepted position papers that share topical similarities but perhaps differences in opinion.</li>
        
        <li><b>Lightning talks</b> are intended for early career researchers or other community members who may be just beginning to launch an idea or project within the context of alt.VIS. We hope to offer the floor to those with curiosity and drive, but perhaps lacking the resources or lengthy development to craft a full-fledged paper or formal talk.</li>

        <li><b>Hands-on activities</b> will be vital to maintaining high energy during the workshop, and integral to building a long-term community around alt.VIS, making the workshop a staple of VIS conferences for years to come. If the conference is primarily in-person, we intend to mitigate under-caffeination and postprandial somnolence with brightly-colored activities, movement around the physical workshop space, and short periods of spirited creative collaboration in small breakout groups.  </li>

        <li><b>Artworks</b> of all mediums will be accepted to alt.VIS. Participatory artworks are encouraged for the development of hands-on activities. Artworks are welcomed in non-traditional formats, and they will be shared on the alt.VIS workshop website, as well as promoted on social media. </li>

        <li><b>Traditional format short- and medium-length papers</b> are welcome at alt.VIS, under the condition that they could not be reasonably published in the main conference or other workshops. Examples based on the previous editions of the workshop are: publication of alternative mediums for visualization, critical reflections (such as criticisms of previous published works, or habits of the VIS community that might be usefully called into question), explorations of negative results, or a survey about the VIS community itself.</li>

        <li><b>Responses or critical papers</b> will allow authors to give a concrete place in which they can critique or challenge the work presented in another paper. The objective of this submission form is to foster discussion and improvement for accepted work. As platforms for critique are scarce in visualization, this experimental submission format will allow submitters to demonstrate how critique might be usefully surfaced in the VIS community. A kind approach to critiques will be requested by everyone involved.</li>
      </ul> -->


      <p>Submissions will be evaluated on clarity, novelty, and their ability to promote productive thought and discussion for the alt.VIS audience.  The purpose of this venue is to provide a place for works that fall outside of the purview of the main VIS paper program, and so submissions that would be more at home in the main track are unlikely to be accepted. Please consider taking a look at the submissions from <a href="2022.html" target="_blank">last year’s alt.VIS 2022</a> for inspiration!
         </p>

      <!-- <p><b>This year, we are introducing the Weirdy Awards which celebrate bizarre or thought-provoking ideas, presentations, or submissions.</b></p> -->

      <p>Accepted submissions will be made publicly available on the workshop’s webpage. Authors are also welcome and encouraged to archive on their repository of choice, e.g. OSF, ArXiv. Submissions will not be archived within the main IEEE VIS conference archive.</p>

      <p>If you are unsure of how to submit your work, or if you want to discuss your submission with us, do not hesitate to contact us at <a rel="noopener noreferrer" target="_blank" href="mailto:alt.vis.workshop@gmail.com" >alt.vis.workshop@gmail.com</a></p>
      <p><em>* Authors serving in this workshop's organizing roles should include a COI statement in their PDF.</em></p>
    </section>
    <p><b>NOTE FOR EU SUBMITTERS:</b> The alt.VIS workshop is <a rel="noopener noreferrer" href="https://www.coalition-s.org/faq-theme/compliance/" target="_blank">Plan S compliant. <img alt="Plan-S Logo" src="img/plan_s.jpeg" width="60px"></a></p>
    
    <section>
      <h1>Previous Editions (and proceedings):</h1>
      <ul>
      <li>
        <a href="2022.html" target="_blank">alt.VIS 2022</a>
      </li>
      <li>
        <a href="2021.html" target="_blank">alt.VIS 2021</a>
      </li>
    </ul>
    </section>

    <h1>Organizers</h1></br></br></br>

    <div class="row justify-content-md-center">
      <div class="col-4">
        <img class="headshot" src="./img/headshots/lonnie_circle.png" alt="Head shot of Lonni Besancon">
        <p class="bio">
          <b>Lonni Besan&ccedil;on</b><br>
          Monash University<br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/lonnibesancon" >@lonnibesancon</a><br>
          <a rel="noopener noreferrer" target="_blank" href="http://lonnibesancon.me/" >lonnibesancon.me</a><br>
        </p>
      </div>
      <div class="col-4">
        <img class="headshot" src="./img/headshots/derya_circle.png" alt="Head shot of Derya Akbaba ">
        <p class="bio">
          <b>Derya Akbaba</b><br>
          Link&#246;ping University<br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/gotdairyya" >@gotdairyya</a><br>
          <a rel="noopener noreferrer" target="_blank" href="https://gotdairyya.github.io/" >gotdairyya.github.io</a><br>
        </p>
      </div>
      <div class="col-4">
        <img class="headshot" src="./img/headshots/andrew_circle.png" alt="Head shot of Andrew McNutt">
        <p class="bio">
          <b>Andrew McNutt</b><br>
          University of Chicago<br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/_mcnutt_" >@_mcnutt_</a><br>
          <a rel="noopener noreferrer" target="_blank" href="https://www.mcnutt.in/" >mcnutt.in</a><br>
        </p>
      </div></div>
      </br></br></br>
      <div class="row justify-content-md-center">
        <div class="col-4">
          <img class="headshot" src="./img/headshots/sara.png" alt="Head shot of Sara Di Bartolomeo">
          <p class="bio">
            <b>Sara Di Bartolomeo</b><br>
            Northeastern University<br>
            <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/sara_picorana" >@sara_picorana</a><br>
            <a rel="noopener noreferrer" target="_blank" href="https://picorana.github.io/" >picorana.github.io</a><br>
          </p>
        </div>
        <div class="col-4">
          <img class="headshot" src="./img/headshots/victor.png" alt="Head shot of Victor Schetinger">
          <p class="bio">
            <b>Victor Schetinger</b><br>
            TU Wien<br>
            <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/VSchetinger" >@VSchetinger</a><br>
            <a rel="noopener noreferrer" target="_blank" href="https://www.cvast.tuwien.ac.at/team/victor-schetinger">tuwien.ac.at/victor-schetinger</a><br>
          </p>
        </div>
    </div>
    <br><br><br>
    <h1>Steering Committee</h1></br></br></br>
    <div class="row justify-content-md-center">
      <div class="col-4">
        <img class="headshot" src="./img/headshots/jane_circle.png" alt="Head shot of Jane Adams">
        <p class="bio">
          <b>Jane Adams</b><br>
          Northeastern University<br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/janelydiaadams" >@JaneLydiaAdams</a><br>
          <a rel="noopener noreferrer" target="_blank" href="http://universalities.com" >universalities.com</a><br>
        </p>
      </div>
      <div class="col-4">
        <img class="headshot" src="./img/headshots/charles_circle.png" alt="Head shot of Charles Perin">
        <p class="bio">
          <b>Charles Perin</b><br>
          University of Victoria<br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/charles_perin" >@charles_perin</a><br>
          <a rel="noopener noreferrer" target="_blank" href="http://charlesperin.net" >charlesperin.net</a><br>
        </p>
      </div>
      <div class="col-4">
        <img class="headshot" src="./img/headshots/michael_circle-01.png">
        <p class="bio">
          <b>Michael Correll</b><br>
          <br>
          <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/Birdbassador" >@Birdbassador</a><br>
          <a target="_blank" href="http://correll.io/" target="_blank">correll.io</a><br>
        </p>
      </div>
    </div>

    <p>Questions? Contact us at <a target="_blank" href="mailto:alt.vis.workshop@gmail.com" >alt.vis.workshop@gmail.com</a>.</p>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.slim.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
